<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="https://judepark96.github.io/feed.xml" rel="self" type="application/atom+xml" /><link href="https://judepark96.github.io/" rel="alternate" type="text/html" /><updated>2021-05-19T01:03:59-05:00</updated><id>https://judepark96.github.io/feed.xml</id><title type="html">Eunhwan Park X NLP</title><subtitle>Eunhwan Park X NLP</subtitle><entry><title type="html">NAVER 인턴십 합격</title><link href="https://judepark96.github.io/retrospective/2021/05/03/naver-internship.html" rel="alternate" type="text/html" title="NAVER 인턴십 합격" /><published>2021-05-03T00:00:00-05:00</published><updated>2021-05-03T00:00:00-05:00</updated><id>https://judepark96.github.io/retrospective/2021/05/03/naver-internship</id><content type="html" xml:base="https://judepark96.github.io/retrospective/2021/05/03/naver-internship.html">&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/1131106/116882366-5a318f00-ac5f-11eb-9316-93681374d701.png&quot; alt=&quot;image&quot; /&gt;&lt;/p&gt;

&lt;p&gt;더 열심히 연구해야지!&lt;/p&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">Single-Hop Question Generation with BART</title><link href="https://judepark96.github.io/nlp,/text/generation/2021/04/08/BART-Single-Hop-Question-Generation.html" rel="alternate" type="text/html" title="Single-Hop Question Generation with BART" /><published>2021-04-08T00:00:00-05:00</published><updated>2021-04-08T00:00:00-05:00</updated><id>https://judepark96.github.io/nlp,/text/generation/2021/04/08/BART-Single-Hop-Question-Generation</id><content type="html" xml:base="https://judepark96.github.io/nlp,/text/generation/2021/04/08/BART-Single-Hop-Question-Generation.html">&lt;p&gt;&lt;img src=&quot;https://user-images.githubusercontent.com/1131106/113915719-11cab100-981a-11eb-8c2b-a7e0b8a9d746.png&quot; alt=&quot;Screen Shot 2021-04-06 at 2 15 00 AM&quot; /&gt;&lt;/p&gt;

&lt;p&gt;KorQuAD 와 AI 기계독해 데이터와 BART를 이용하여 질문 생성 실험을 해보았다. 생각보다 결과가 좋게 나온 것 같다.
이제 이러한 실험을 바탕으로 더욱 더 확장해보아야겠다.&lt;/p&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">UAS, LAS 정의</title><link href="https://judepark96.github.io/nlp,/torch/2021/03/05/uas-las.html" rel="alternate" type="text/html" title="UAS, LAS 정의" /><published>2021-03-05T00:00:00-06:00</published><updated>2021-03-05T00:00:00-06:00</updated><id>https://judepark96.github.io/nlp,/torch/2021/03/05/uas-las</id><content type="html" xml:base="https://judepark96.github.io/nlp,/torch/2021/03/05/uas-las.html">&lt;ul&gt;
  &lt;li&gt;UAS (Unlabeled attachment score) : Percentage of words that get the correct head&lt;/li&gt;
  &lt;li&gt;LAS (Labeled attachment score) : Percentage of words that get the correct head and label&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">UAS (Unlabeled attachment score) : Percentage of words that get the correct head LAS (Labeled attachment score) : Percentage of words that get the correct head and label</summary></entry><entry><title type="html">How to load weight of the part of a pre-trained model in PyTorch?</title><link href="https://judepark96.github.io/nlp,/torch/2021/02/22/load-weight-manually.html" rel="alternate" type="text/html" title="How to load weight of the part of a pre-trained model in PyTorch?" /><published>2021-02-22T00:00:00-06:00</published><updated>2021-02-22T00:00:00-06:00</updated><id>https://judepark96.github.io/nlp,/torch/2021/02/22/load-weight-manually</id><content type="html" xml:base="https://judepark96.github.io/nlp,/torch/2021/02/22/load-weight-manually.html">&lt;p&gt;We usually do pre-train language models but depends on model configuration, there need to load weight manually. For example, what if we have weights of 6 layers and the structure of the given pre-trained model is 12 layers, then how to load the weights into the given pre-trained model?&lt;/p&gt;

&lt;p&gt;Usually, there is a succinct method to load weights; &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;load_state_dict()&lt;/code&gt;. But, mentioned above, we can’t use &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;load_state_dict()&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Here is the thing;&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;model&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;lm_dict&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;items&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lm_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;lm_dict&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;update&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;weights&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;lm&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;load_state_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;lm_dict&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;</content><author><name></name></author><summary type="html">We usually do pre-train language models but depends on model configuration, there need to load weight manually. For example, what if we have weights of 6 layers and the structure of the given pre-trained model is 12 layers, then how to load the weights into the given pre-trained model?</summary></entry><entry><title type="html">국민대학교를 드디어 졸업했어요.</title><link href="https://judepark96.github.io/graduation/2021/02/20/%EA%B5%AD%EB%AF%BC%EB%8C%80%ED%95%99%EA%B5%90%EB%A5%BC-%EB%93%9C%EB%94%94%EC%96%B4-%EC%A1%B8%EC%97%85%ED%96%88%EC%96%B4%EC%9A%94.html" rel="alternate" type="text/html" title="국민대학교를 드디어 졸업했어요." /><published>2021-02-20T00:00:00-06:00</published><updated>2021-02-20T00:00:00-06:00</updated><id>https://judepark96.github.io/graduation/2021/02/20/%EA%B5%AD%EB%AF%BC%EB%8C%80%ED%95%99%EA%B5%90%EB%A5%BC%20%EB%93%9C%EB%94%94%EC%96%B4%20%EC%A1%B8%EC%97%85%ED%96%88%EC%96%B4%EC%9A%94</id><content type="html" xml:base="https://judepark96.github.io/graduation/2021/02/20/%EA%B5%AD%EB%AF%BC%EB%8C%80%ED%95%99%EA%B5%90%EB%A5%BC-%EB%93%9C%EB%94%94%EC%96%B4-%EC%A1%B8%EC%97%85%ED%96%88%EC%96%B4%EC%9A%94.html">&lt;p&gt;&lt;img src=&quot;https://github.com/JudePark96/judepark96.github.io/blob/master/_posts/graduation/graduation.jpg?raw=true&quot; width=&quot;600&quot; height=&quot;600&quot; /&gt;&lt;/p&gt;

&lt;p&gt;드디어 국민대학교를 졸업하였습니다. 이 추운 날 학교 와줘서 축하해준 친구들 너무 고맙습니다. 국민대학교를 다니며 좋은 친구들 덕분에 그 무엇보다 &lt;strong&gt;“노력”&lt;/strong&gt; 과 &lt;strong&gt;“겸손”&lt;/strong&gt; 의 가치를 보다 더 깨달을 수 있었습니다. 학교의 미국 연수 프로그램 덕분에 좋은 경험들도 할 수 있었죠. 미국 연수 이후 영어 실력이 좋아져서 지금까지도 논문을 읽는데 있어 굉장히 큰 도움이 되고 있습니다.&lt;/p&gt;

&lt;p&gt;어찌어찌 졸업을 하였고, 이런 부족한 저도 지금은 대학원에 들어가 석사 과정 학생으로서 다시 한 번 공부하려고 합니다. 정든 학교를 떠나는 건 마음이 아프지만, 그럼에도 졸업은 필연이니 이젠 국민대학교 졸업생으로서 더욱 더 열심히 해야겠죠. 학부 생활동안 너무나도 행복했고 교수님들, 선배님들, 동기, 친구들 모두 너무 감사드리고 배운 걸 바탕으로 석사 과정 열심히 공부해서 자연어처리 좋은 연구하도록 노력할게요. 모두 감사합니다!&lt;/p&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">mecab-ko-dic 컴파일 에러 해결하기</title><link href="https://judepark96.github.io/natural/language/processing,/nlp/2021/02/20/mecab-ko-dic-%EC%BB%B4%ED%8C%8C%EC%9D%BC-%EC%97%90%EB%9F%AC-%ED%95%B4%EA%B2%B0%ED%95%98%EA%B8%B0.html" rel="alternate" type="text/html" title="mecab-ko-dic 컴파일 에러 해결하기" /><published>2021-02-20T00:00:00-06:00</published><updated>2021-02-20T00:00:00-06:00</updated><id>https://judepark96.github.io/natural/language/processing,/nlp/2021/02/20/mecab-ko-dic%20%EC%BB%B4%ED%8C%8C%EC%9D%BC%20%EC%97%90%EB%9F%AC%20%ED%95%B4%EA%B2%B0%ED%95%98%EA%B8%B0</id><content type="html" xml:base="https://judepark96.github.io/natural/language/processing,/nlp/2021/02/20/mecab-ko-dic-%EC%BB%B4%ED%8C%8C%EC%9D%BC-%EC%97%90%EB%9F%AC-%ED%95%B4%EA%B2%B0%ED%95%98%EA%B8%B0.html">&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;WARNING: `aclocal-1.11' is missing on your system. You should only need it if you modified`acinclude.m4' or `configure.ac'. You might want to install the`Automake' and `Perl' packages. Grab them from any GNU archive site. configure.ac:2: error: possibly undefined macro: AM_INIT_AUTOMAKE If this token and others are legitimate, please use m4_pattern_allow. See the Autoconf documentation. make: ***
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;./configure&lt;/code&gt; 와 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;make&lt;/code&gt; 을 하였을 때 위와 같은 에러로 MeCab 사전이 컴파일되지 않는 경우가 발생한다. 그럴 경우에는 아래와 같이 하면 된다.&lt;/p&gt;

&lt;div class=&quot;language-bash highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;autoreconf
./configure
make
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;아마도 autoconf, automake 관련 에러로 생각되는데 autoreconf 를 하면 잘 된다.&lt;/p&gt;</content><author><name></name></author><summary type="html">WARNING: `aclocal-1.11' is missing on your system. You should only need it if you modified`acinclude.m4' or `configure.ac'. You might want to install the`Automake' and `Perl' packages. Grab them from any GNU archive site. configure.ac:2: error: possibly undefined macro: AM_INIT_AUTOMAKE If this token and others are legitimate, please use m4_pattern_allow. See the Autoconf documentation. make: ***</summary></entry><entry><title type="html">簡単な卒業の感想</title><link href="https://judepark96.github.io/2020/12/11/%E7%B0%A1%E5%8D%98%E3%81%AA%E5%8D%92%E6%A5%AD%E3%81%AE%E6%84%9F%E6%83%B3.html" rel="alternate" type="text/html" title="簡単な卒業の感想" /><published>2020-12-11T00:00:00-06:00</published><updated>2020-12-11T00:00:00-06:00</updated><id>https://judepark96.github.io/2020/12/11/%E7%B0%A1%E5%8D%98%E3%81%AA%E5%8D%92%E6%A5%AD%E3%81%AE%E6%84%9F%E6%83%B3</id><content type="html" xml:base="https://judepark96.github.io/2020/12/11/%E7%B0%A1%E5%8D%98%E3%81%AA%E5%8D%92%E6%A5%AD%E3%81%AE%E6%84%9F%E6%83%B3.html">&lt;p&gt;そろそろ卒業の時間が来る。&lt;/p&gt;

&lt;p&gt;良いことも、悪い事もありましたけど何か未来が期待される。&lt;/p&gt;

&lt;p&gt;新しいもの研究室に挑戦である。&lt;/p&gt;

&lt;p&gt;未来には良いことだけ！！！&lt;/p&gt;

&lt;p&gt;：ジュドさんは日本語の練習中。
：日本語 Level １。&lt;/p&gt;</content><author><name></name></author><summary type="html">そろそろ卒業の時間が来る。</summary></entry><entry><title type="html">Linear Independence and Dependence</title><link href="https://judepark96.github.io/linear/algebra/2020/11/22/Linear-Independence-and-Dependence.html" rel="alternate" type="text/html" title="Linear Independence and Dependence" /><published>2020-11-22T00:00:00-06:00</published><updated>2020-11-22T00:00:00-06:00</updated><id>https://judepark96.github.io/linear/algebra/2020/11/22/Linear%20Independence%20and%20Dependence</id><content type="html" xml:base="https://judepark96.github.io/linear/algebra/2020/11/22/Linear-Independence-and-Dependence.html">&lt;p&gt;If $S = {v_1, v_2, …, v_r}$ is a nonempty set of vectors in a vector space $V$, then the vector equation:
&lt;script type=&quot;math/tex&quot;&gt;k_1v_1 + k_2v_2+ ... + k_rv_r = 0&lt;/script&gt;
has at least one solution, namely,
&lt;script type=&quot;math/tex&quot;&gt;k_1=0, k_2=0, ..., k_r =0&lt;/script&gt;
We call this the trivial solution. If this is the only solution, then $S$ is said to be a &lt;strong&gt;linearly independent set&lt;/strong&gt;. if there are solutions in addition to the trivial solution then S is said to be a &lt;strong&gt;Linearly dependent set&lt;/strong&gt;&lt;/p&gt;

&lt;h1 id=&quot;reference&quot;&gt;Reference&lt;/h1&gt;

&lt;ul&gt;
  &lt;li&gt;Elementary Linear Algebra with Supplemental Applications 11th, Howard Anton, Chris Rorres. 186p&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">If $S = {v_1, v_2, …, v_r}$ is a nonempty set of vectors in a vector space $V$, then the vector equation: has at least one solution, namely, We call this the trivial solution. If this is the only solution, then $S$ is said to be a linearly independent set. if there are solutions in addition to the trivial solution then S is said to be a Linearly dependent set</summary></entry><entry><title type="html">.gitignore 가 동작하지 않아! 어떻게 해야해!?</title><link href="https://judepark96.github.io/github,/git/2020/09/15/gitignore-not-working.html" rel="alternate" type="text/html" title=".gitignore 가 동작하지 않아! 어떻게 해야해!?" /><published>2020-09-15T00:00:00-05:00</published><updated>2020-09-15T00:00:00-05:00</updated><id>https://judepark96.github.io/github,/git/2020/09/15/gitignore-not-working</id><content type="html" xml:base="https://judepark96.github.io/github,/git/2020/09/15/gitignore-not-working.html">&lt;h2 id=&quot;1-어떤-문제가-발생했어&quot;&gt;1. 어떤 문제가 발생했어?&lt;/h2&gt;

&lt;p&gt;나는 항상 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;.gitignore&lt;/code&gt; 를 작성하고 프로젝트를 시작하는데 용량이 큰 바이너리 파일, 불필요한 환경 구축 폴더 등을 올리지 않기 위해서다. 그런데 평소대로 했는데 .gitignore 에 작성한대로 동작을 하지 않았다&lt;/p&gt;

&lt;h2 id=&quot;2-어떻게-해결해&quot;&gt;2. 어떻게 해결해?&lt;/h2&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;git &lt;span class=&quot;nb&quot;&gt;rm&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;-r&lt;/span&gt; &lt;span class=&quot;nt&quot;&gt;--cached&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;
git add &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;
git commit &lt;span class=&quot;nt&quot;&gt;-m&lt;/span&gt; &lt;span class=&quot;s2&quot;&gt;&quot;remove git cached files&quot;&lt;/span&gt;
git push origin master
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이러면 해결이 되더라…!&lt;/p&gt;</content><author><name></name></author><summary type="html">1. 어떤 문제가 발생했어?</summary></entry><entry><title type="html">TorchText Field 의 batch_first 는 항상 True 로 설정하자</title><link href="https://judepark96.github.io/nlp,/torch,/torchtext/2020/08/25/torchtext-field-batch-first.html" rel="alternate" type="text/html" title="TorchText Field 의 batch_first 는 항상 True 로 설정하자" /><published>2020-08-25T00:00:00-05:00</published><updated>2020-08-25T00:00:00-05:00</updated><id>https://judepark96.github.io/nlp,/torch,/torchtext/2020/08/25/torchtext-field-batch-first</id><content type="html" xml:base="https://judepark96.github.io/nlp,/torch,/torchtext/2020/08/25/torchtext-field-batch-first.html">&lt;h2 id=&quot;1-소개&quot;&gt;1. 소개&lt;/h2&gt;

&lt;p&gt;우선 평소에 따로 vocabulary, tokenizer 등의 데이터 전처리 과정에서 필요한 요소들을 직접 코딩해왔었다. 하지만, 이번에는 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;TorchText&lt;/code&gt; 를 한 번 사용해보고자 했다. 그 과정에서 나의 어이없는 실수를 소개한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;한줄 요약: torchtext.data.Field() 를 사용할 때 항상 batch_first=True 로 설정하자.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;2-어떤-문제가-발생했어&quot;&gt;2. 어떤 문제가 발생했어?&lt;/h2&gt;

&lt;p&gt;우선 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;json&lt;/code&gt; 학습 데이터를 구축해놓고 이를 TorchText 를 통하여 불렀다. 학습 데이터의 내부 구조는 아래와 같다.&lt;/p&gt;

&lt;div class=&quot;language-json highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;'text':'text'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;'label':&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;'label'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;...&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;&lt;span class=&quot;err&quot;&gt;'text':'text'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;'label':&lt;/span&gt;&lt;span class=&quot;w&quot;&gt; &lt;/span&gt;&lt;span class=&quot;err&quot;&gt;'label'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;}&lt;/span&gt;&lt;span class=&quot;w&quot;&gt;
&lt;/span&gt;&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이제 어떻게 불러오는지 한 번 보자.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torchtext.data&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Iterator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TabularDataset&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;SRC&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot; &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lower&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_first&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;TRG&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Field&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenize&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;split&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;&quot; &quot;&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;init_token&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&amp;lt;sos&amp;gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;eos_token&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'&amp;lt;eos&amp;gt;'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;lower&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_first&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;True&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TabularDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;path&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'data.json'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                         &lt;span class=&quot;nb&quot;&gt;format&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'json'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
                         &lt;span class=&quot;n&quot;&gt;fields&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;{&lt;/span&gt;
                                 &lt;span class=&quot;s&quot;&gt;'text'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'text'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;SRC&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; 
                                 &lt;span class=&quot;s&quot;&gt;'label'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;'label'&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;TRG&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)}&lt;/span&gt;
                        &lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;우선 SRC와 TRG에 해당하는 Field 를 설정한다. TorchText 에서는 Field 내부의 속성들을 지정함으로서 데이터 전처리 의 번거로움을 줄여준다고 한다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;위의 코드에선 batch_first=True 로 하였다. False 일 때와 차이점을 아래에서 보여줄 예정이다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이제 우리가 일상적으로 사용하는 텐서의 형태로 보기 위해서는 아래와 같이 코드를 작성한다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;SRC&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;build_vocab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;TRG&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;build_vocab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;우리가 만들었어야하는 vocabulary 를 위의 2줄로 만들 수가 있다. 옴마가쉬… 그 외에도 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;min_freq&lt;/code&gt; 와 같은 속성으로 vocabulary 생성 과정에 조건을 걸 수 있다.&lt;/p&gt;

&lt;p&gt;이제 iterator 로 돌려보고 결과를 보자.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;n&quot;&gt;BATCH_SIZE&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;

&lt;span class=&quot;n&quot;&gt;train_iterator&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BucketIterator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;BATCH_SIZE&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;
&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;train_iterator&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
	  &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;' '&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;SRC&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;itos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;text&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]))&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;s&quot;&gt;' '&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;join&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;TRG&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;itos&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;item&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()]&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;label&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;0&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]))&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;text -&amp;gt; to &lt;span class=&quot;nb&quot;&gt;date&lt;/span&gt; , a large number of ... have been stated and the most appropriate algorithm &lt;span class=&quot;k&quot;&gt;for &lt;/span&gt;each application has been determined &lt;span class=&quot;nb&quot;&gt;.&lt;/span&gt;

label -&amp;gt; &amp;lt;sos&amp;gt; autonomous exploration __&lt;span class=&quot;p&quot;&gt;;&lt;/span&gt;__ mapping of unknown environments &amp;lt;eos&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;대충 의도한대로 제대로 나왔다. 그렇다면 만약 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;batch_first=False&lt;/code&gt; 로 설정한다면 어떻게 될까?&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;텍스트 길이가 길기 때문에 일부 텍스트와 패딩 토큰을 보기 좋게 하기 위하여 지웠다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;div class=&quot;language-shell highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&amp;lt;sos&amp;gt; &amp;lt;sos&amp;gt; &amp;lt;sos&amp;gt; &amp;lt;sos&amp;gt; &amp;lt;sos&amp;gt; &amp;lt;sos&amp;gt; &amp;lt;sos&amp;gt; &amp;lt;sos&amp;gt;
&amp;lt;sos&amp;gt; &amp;lt;sos&amp;gt; &amp;lt;sos&amp;gt; &amp;lt;sos&amp;gt; &amp;lt;sos&amp;gt; &amp;lt;sos&amp;gt; &amp;lt;sos&amp;gt; &amp;lt;sos&amp;gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;batch_first=False&lt;/code&gt; 를 하였을 때는 위처럼 나오게 된다. 옴마가쉬…&lt;/p&gt;

&lt;h2 id=&quot;3-여기서-나의-실수는&quot;&gt;3. 여기서 나의 실수는?&lt;/h2&gt;

&lt;p&gt;많은 예제들, 그리고 나의 경험에서 나는 항상 데이터 전처리 과정에서 텐서의 형상을 $\text{batch_size} \ntimes \text{sequence_length}$ 의 형태를 띄도록 하였다. 하지만 TorchText 에서는 $\text{sequence_length} \ntimes \text{batch_size}$ 의 형태 또한 지원했던 것이다. 그렇기 때문에 Index -&amp;gt; Text 로 변환하였을 때 제대로 표현이 안되었던 것이다. 홀리쉿…&lt;/p&gt;

&lt;h2 id=&quot;4-결론&quot;&gt;4. 결론&lt;/h2&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;strong&gt;batch_first&lt;/strong&gt; 속성을 확인하자.&lt;/li&gt;
  &lt;li&gt;TorchText 는 좋은 거다. 나름대로.&lt;/li&gt;
  &lt;li&gt;토큰화 과정은 &lt;strong&gt;따로 전처리하는 것&lt;/strong&gt;이 나은 것 같다.&lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">1. 소개</summary></entry></feed>