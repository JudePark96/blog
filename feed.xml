<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="3.8.5">Jekyll</generator><link href="https://judepark96.github.io/blog/feed.xml" rel="self" type="application/atom+xml" /><link href="https://judepark96.github.io/blog/" rel="alternate" type="text/html" /><updated>2020-06-19T10:18:09-05:00</updated><id>https://judepark96.github.io/blog/feed.xml</id><title type="html">Eunhwan Park X NLP</title><subtitle>Eunhwan Park X NLP</subtitle><entry><title type="html">Sigmoid Derivation</title><link href="https://judepark96.github.io/blog/%EB%AF%B8%EB%B6%84/2020/06/06/sigmoid.html" rel="alternate" type="text/html" title="Sigmoid Derivation" /><published>2020-06-06T00:00:00-05:00</published><updated>2020-06-06T00:00:00-05:00</updated><id>https://judepark96.github.io/blog/%EB%AF%B8%EB%B6%84/2020/06/06/sigmoid</id><content type="html" xml:base="https://judepark96.github.io/blog/%EB%AF%B8%EB%B6%84/2020/06/06/sigmoid.html">&lt;script type=&quot;math/tex; mode=display&quot;&gt;y = \frac{1}{1+e^{-x}}&lt;/script&gt;

&lt;p&gt;우선 $u = 1+e^{-x}$ 로 한다면 아래와 같이 된다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;y = \frac{1}{u}&lt;/script&gt;

&lt;p&gt;이제 이를 미분하는 과정은 아래와 같다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;\frac{dy}{du}(u^{-1})\frac{du}{dx}(1+e^{-x}) \\
=-u^{-2} (-e^{-x}) \\
=\frac{e^{-x}}{(1+e^{-x})^2} \\
=y(1-y)&lt;/script&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">여름 방학동안 뭐하지 ?</title><link href="https://judepark96.github.io/blog/%EC%97%AC%EB%A6%84%EB%B0%A9%ED%95%99,/%EB%8C%80%ED%95%99%EC%83%9D/2020/05/30/%EC%97%AC%EB%A6%84%EB%B0%A9%ED%95%99.html" rel="alternate" type="text/html" title="여름 방학동안 뭐하지 ?" /><published>2020-05-30T00:00:00-05:00</published><updated>2020-05-30T00:00:00-05:00</updated><id>https://judepark96.github.io/blog/%EC%97%AC%EB%A6%84%EB%B0%A9%ED%95%99,/%EB%8C%80%ED%95%99%EC%83%9D/2020/05/30/%EC%97%AC%EB%A6%84%EB%B0%A9%ED%95%99</id><content type="html" xml:base="https://judepark96.github.io/blog/%EC%97%AC%EB%A6%84%EB%B0%A9%ED%95%99,/%EB%8C%80%ED%95%99%EC%83%9D/2020/05/30/%EC%97%AC%EB%A6%84%EB%B0%A9%ED%95%99.html">&lt;p&gt;이번 글만큼은 약간 러프한 나의 생각을 나열해보자! 러프한 생각 나열이니 글씨 말투도 러프하게 하자!&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;회사 인턴&lt;/li&gt;
  &lt;li&gt;AI Rush&lt;/li&gt;
  &lt;li&gt;인라이플 KorQuAD Challenge 마무리&lt;/li&gt;
  &lt;li&gt;EmotionGIF 2020&lt;/li&gt;
  &lt;li&gt;밑바닥부터 시작하는 딥러닝 1~2 복습&lt;/li&gt;
  &lt;li&gt;기초 수학 복습&lt;/li&gt;
  &lt;li&gt;운동 (aka. 건강한 삶)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;연구와 관련된 모든 것을 지탱할 수 있는 나의 비장의 무기.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/JudePark96/blog/master/images/tfrc_tpu.png&quot; alt=&quot;trfc&quot; /&gt;&lt;/p&gt;

&lt;p&gt;하하하하!!! 꺄르륵!!! 내가 지금까지 이걸 아껴두고 있었지!!!&lt;/p&gt;

&lt;p&gt;열심히 해야징 쿄쿄쿄…&lt;/p&gt;</content><author><name></name></author><summary type="html">이번 글만큼은 약간 러프한 나의 생각을 나열해보자! 러프한 생각 나열이니 글씨 말투도 러프하게 하자!</summary></entry><entry><title type="html">프로그래머스 - 모의고사 (Python)</title><link href="https://judepark96.github.io/blog/algorithm/2020/05/16/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EC%8A%A4-%EB%AA%A8%EC%9D%98%EA%B3%A0%EC%82%AC-(Python).html" rel="alternate" type="text/html" title="프로그래머스 - 모의고사 (Python)" /><published>2020-05-16T00:00:00-05:00</published><updated>2020-05-16T00:00:00-05:00</updated><id>https://judepark96.github.io/blog/algorithm/2020/05/16/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EC%8A%A4%20-%20%EB%AA%A8%EC%9D%98%EA%B3%A0%EC%82%AC%20(Python)</id><content type="html" xml:base="https://judepark96.github.io/blog/algorithm/2020/05/16/%ED%94%84%EB%A1%9C%EA%B7%B8%EB%9E%98%EB%A8%B8%EC%8A%A4-%EB%AA%A8%EC%9D%98%EA%B3%A0%EC%82%AC-(Python).html">&lt;h2 id=&quot;문제-설명&quot;&gt;문제 설명&lt;/h2&gt;

&lt;p&gt;수포자는 수학을 포기한 사람의 준말입니다. 수포자 삼인방은 모의고사에 수학 문제를 전부 찍으려 합니다. 수포자는 1번 문제부터 마지막 문제까지 다음과 같이 찍습니다.&lt;/p&gt;

&lt;p&gt;1번 수포자가 찍는 방식: 1, 2, 3, 4, 5, 1, 2, 3, 4, 5, …
2번 수포자가 찍는 방식: 2, 1, 2, 3, 2, 4, 2, 5, 2, 1, 2, 3, 2, 4, 2, 5, …
3번 수포자가 찍는 방식: 3, 3, 1, 1, 2, 2, 4, 4, 5, 5, 3, 3, 1, 1, 2, 2, 4, 4, 5, 5, …&lt;/p&gt;

&lt;p&gt;1번 문제부터 마지막 문제까지의 정답이 순서대로 들은 배열 answers가 주어졌을 때, 가장 많은 문제를 맞힌 사람이 누구인지 배열에 담아 return 하도록 solution 함수를 작성해주세요.&lt;/p&gt;

&lt;h5 id=&quot;제한-조건&quot;&gt;제한 조건&lt;/h5&gt;

&lt;ul&gt;
  &lt;li&gt;시험은 최대 10,000 문제로 구성되어있습니다.&lt;/li&gt;
  &lt;li&gt;문제의 정답은 1, 2, 3, 4, 5중 하나입니다.&lt;/li&gt;
  &lt;li&gt;가장 높은 점수를 받은 사람이 여럿일 경우, return하는 값을 오름차순 정렬해주세요.&lt;/li&gt;
&lt;/ul&gt;

&lt;h5 id=&quot;입출력-예&quot;&gt;입출력 예&lt;/h5&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;answers&lt;/th&gt;
      &lt;th&gt;return&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;[1,2,3,4,5]&lt;/td&gt;
      &lt;td&gt;[1]&lt;/td&gt;
    &lt;/tr&gt;
    &lt;tr&gt;
      &lt;td&gt;[1,3,2,4,2]&lt;/td&gt;
      &lt;td&gt;[1,2,3]&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;h5 id=&quot;입출력-예-설명&quot;&gt;입출력 예 설명&lt;/h5&gt;

&lt;p&gt;입출력 예 #1&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;수포자 1은 모든 문제를 맞혔습니다.&lt;/li&gt;
  &lt;li&gt;수포자 2는 모든 문제를 틀렸습니다.&lt;/li&gt;
  &lt;li&gt;수포자 3은 모든 문제를 틀렸습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;따라서 가장 문제를 많이 맞힌 사람은 수포자 1입니다.&lt;/p&gt;

&lt;p&gt;입출력 예 #2&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;모든 사람이 2문제씩을 맞췄습니다.&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&quot;문제-풀이&quot;&gt;문제 풀이&lt;/h2&gt;

&lt;p&gt;이 문제의 theme 은 &lt;strong&gt;완전탐색&lt;/strong&gt;이다. 주어진 패턴과 답안을 비교하며 맞은 수를 각 수포자마다 기록하고 형식에 맞게만 반환해주면 되는 문제이다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;solution&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;answers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;p1&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;answers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;p2&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;answers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;8&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;p3&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;4&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;5&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;*&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;answers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;/&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;10&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;))&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;calc&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;sum&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;map&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;k&quot;&gt;lambda&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;x&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;y&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)))&lt;/span&gt;

    &lt;span class=&quot;n&quot;&gt;result_list&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;calc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p1&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;answers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;calc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;answers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;),&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;calc&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;p3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;answers&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)]&lt;/span&gt;
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;i&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;1&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;i&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;enumerate&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;if&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;max&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;result_list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;result&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;수포자가 찍는 방식을 패턴이라고 하자. 그렇다면 그 패턴은 최소한 &lt;strong&gt;패턴 *= (정답 수 / 패턴 길이) + 1&lt;/strong&gt; 만큼 될 것이다. &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;p1~p3&lt;/code&gt; 가 그렇게 초기화된 것이다.&lt;/p&gt;

&lt;p&gt;그리고 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;calc&lt;/code&gt; 이라는 lambda function 을 선언해준다. 이 lambda function 에서 맞은 것을 기록하며 만약 5개 중 2개가 맞았다면 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[True, False, True, False, False]&lt;/code&gt; 와 같은 방식으로 기록될 것이다. (이것은 예시일 뿐이다.) 그렇다면 이 배열을 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;sum&lt;/code&gt; 함수로 계산하면 2가 될 것이다.&lt;/p&gt;

&lt;p&gt;그리고 답안 형태에 맞게 변환해주고 반환해주면 정답이 풀린다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Python 의 Generator 를 이용하면 (cycle 과 같은) 공간복잡도 또한 해결할 수 있으나, 최대 10,000 문제라는 조건과 쉬운 문제의 특성 상 cycle 을 사용하지 않았다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;출처&quot;&gt;출처&lt;/h2&gt;

&lt;p&gt;&lt;a href=&quot;https://programmers.co.kr/learn/courses/30/lessons/42840&quot;&gt;프로그래머스 - 모의고사&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><summary type="html">문제 설명</summary></entry><entry><title type="html">Supervised Learning, Linear Regression</title><link href="https://judepark96.github.io/blog/machine-learning/supervised-learning/2020/05/03/Supervised-Learning-1.html" rel="alternate" type="text/html" title="Supervised Learning, Linear Regression" /><published>2020-05-03T00:00:00-05:00</published><updated>2020-05-03T00:00:00-05:00</updated><id>https://judepark96.github.io/blog/machine-learning/supervised-learning/2020/05/03/Supervised%20Learning-1</id><content type="html" xml:base="https://judepark96.github.io/blog/machine-learning/supervised-learning/2020/05/03/Supervised-Learning-1.html">&lt;h3 id=&quot;1-supervised-learning&quot;&gt;1. Supervised Learning&lt;/h3&gt;

&lt;p&gt;Supervised Learning 이란 주어진 $feature X$ 를 이용하여 $target Y$ 를 예측하는 것이다. $(x_i, y_i)$ 는 하나의 training example 이며 ${(x_i, y_i);i = 1, …, n}$ 를 training set 으로 표현할 수 있다.&lt;/p&gt;

&lt;p&gt;위의 Notation 을 바탕으로 정리하자면 주어진 training set 을 바탕으로 $target Y$ 를 예측하는 $h(x)$ 를 학습하는 것이다. 이 $h(x)$ 를 Hypothesis 라고  부른다.&lt;/p&gt;

&lt;p&gt;$target Y$ 가 continuous 하다면 regression problem 이고, $target Y$ 가 discrete 하다면 classification problem 으로 부를 수 있다.&lt;/p&gt;

&lt;h3 id=&quot;2-linear-regression&quot;&gt;2. Linear Regression&lt;/h3&gt;

&lt;p&gt;$X$ 가 2개의 feature 를 가지고 있다고 하자. 그렇다면 $h(x)$ 는 아래와 같이 될 수 있다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;h(x) = \theta_0 + \theta_1x_1 + \theta_2x_2&lt;/script&gt;

&lt;p&gt;위의 수식은 linear function 을 통하여 y 로 approximate 하는 것이다. 여기서 $\theta$ 는 parameters 이며 weights 로도 불린다. 이 $\theta$ 는 $x$ 를 $y$ 로 vector space 에서 mapping 하는 것을 의미하며 그렇기 때문에 $\theta$ 가 잘 학습되는 것이 중요하다.&lt;/p&gt;

&lt;p&gt;어떻게 좋은 $\theta$ 를 얻을 수 있을까? Linear Regression 을 하는 목적은 주어진 $feature X$ 를 이용하여 $target Y$ 에 근사시키는 것이다. 이를 위해 &lt;strong&gt;Cost Function&lt;/strong&gt; 을 사용한다. 수식은 아래와 같다.&lt;/p&gt;

&lt;p&gt;$J(\theta) = \frac{1}{2}\sum_{i=1}^n(h_{\theta}(x^{i}) - y^i)^2 $&lt;/p&gt;

&lt;p&gt;Ordinary Least Squares 를 의미하며 수식을 직관적으로 바라보면 $h(x^i)$ 와 $y^i$ 간의 잔차를 제곱한 것이다. 이는 $y$ 와 $h_{\theta}(x)$ 간의 error 를 의미하며 좋은 $\theta$ 를 얻기 위해서 error 를 줄여야할 것이다.&lt;/p&gt;

&lt;p&gt;우리는 $J(\theta)$ 를 최소화(minimize)하는 $\theta$ 를 찾고 싶다. 그렇기 때문에 &lt;strong&gt;Gradient Descent&lt;/strong&gt; 를 사용한다.&lt;/p&gt;

&lt;p&gt;$\theta_j := \theta_j - \alpha \frac{\partial}{\partial\theta_j}J(\theta)$&lt;/p&gt;

&lt;p&gt;$\alpha$ 는 learning rate 를 의미한다. 매 step 마다 $J(\theta)$ 를 최소화할 것이며 결국 수렴할 것이다. right hand side 의 partial derivative term 을 풀어보면 아래와 같다.&lt;/p&gt;

&lt;p&gt;$\frac{\partial}{\partial\theta_j}J(\theta) = (h_\theta(x) - y)x_j$&lt;/p&gt;

&lt;p&gt;그렇기 때문에 update rule 은 아래와 같다.&lt;/p&gt;

&lt;p&gt;$\theta_j := \theta_j + \alpha(y^i-h_{\theta}(x^i)x^i_j))$&lt;/p&gt;

&lt;p&gt;위의 rule 을 &lt;strong&gt;least mean squares update rule&lt;/strong&gt; 이라고 불린다.&lt;/p&gt;

&lt;h3 id=&quot;3-conclusion&quot;&gt;3. Conclusion&lt;/h3&gt;

&lt;ol&gt;
  &lt;li&gt;Supervised Learning 은 $h(x) :\rightarrow Y$, 즉 $y$ 로 근사시키는 $h(x)$ 를 만드는 것이다.&lt;/li&gt;
  &lt;li&gt;$J(\theta)$ 를 minimize 하기 위하여 Gradient Descent 를 사용한다.&lt;/li&gt;
  &lt;li&gt;Linear Regression 에서 update rule 로서 least mean squares update rule 을 사용한다.&lt;/li&gt;
&lt;/ol&gt;</content><author><name></name></author><summary type="html">1. Supervised Learning</summary></entry><entry><title type="html">Real-Time Checking NVIDIA-SMI</title><link href="https://judepark96.github.io/blog/deep-learning/2020/04/30/Real-Time-Checking-NVIDIA-SMI.html" rel="alternate" type="text/html" title="Real-Time Checking NVIDIA-SMI" /><published>2020-04-30T00:00:00-05:00</published><updated>2020-04-30T00:00:00-05:00</updated><id>https://judepark96.github.io/blog/deep-learning/2020/04/30/Real-Time-Checking-NVIDIA-SMI</id><content type="html" xml:base="https://judepark96.github.io/blog/deep-learning/2020/04/30/Real-Time-Checking-NVIDIA-SMI.html">&lt;h2 id=&quot;1-introduction&quot;&gt;1. Introduction&lt;/h2&gt;

&lt;p&gt;딥러닝 신경망을 학습하다보면 GPU 상태를 확인해볼 필요가 있다. 그 명령어가 &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;nvidia-smi&lt;/code&gt; 인데 이거를 매번 타이핑하는 것은 굉장히 비효율적인 행동이다. 리눅스 명령어를 통하여 실시간 모니터링이 가능하도록 하자.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;cuda 관련 환경 구축이 전부 되어있음을 가정한다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h2 id=&quot;2-monitoring&quot;&gt;2. Monitoring&lt;/h2&gt;

&lt;p&gt;아래의 명령어를 터미널에서 타이핑한다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;watch -d -n 0.5 nvidia-smi&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;그러면 아래와 같이 화면이 나온다.&lt;/p&gt;

&lt;p&gt;&lt;img src=&quot;https://raw.githubusercontent.com/JudePark96/blog/master/images/nvidia-smi.png&quot; alt=&quot;nvidia-smi&quot; /&gt;&lt;/p&gt;

&lt;p&gt;위의 명령어는 nvidia-smi 를 0.5초에 한 번씩 새로고침되도록 하는 명령어이다. 이를 통하여 실시간 모니터링이 가능하다.&lt;/p&gt;</content><author><name></name></author><summary type="html">1. Introduction</summary></entry><entry><title type="html">Python - DataClasses Package</title><link href="https://judepark96.github.io/blog/python/2020/04/21/Python-DataClasses-Package.html" rel="alternate" type="text/html" title="Python - DataClasses Package" /><published>2020-04-21T00:00:00-05:00</published><updated>2020-04-21T00:00:00-05:00</updated><id>https://judepark96.github.io/blog/python/2020/04/21/Python-DataClasses-Package</id><content type="html" xml:base="https://judepark96.github.io/blog/python/2020/04/21/Python-DataClasses-Package.html">&lt;h2 id=&quot;1-introduction&quot;&gt;1. Introduction&lt;/h2&gt;

&lt;p&gt;Java 로 개발하던 때에는 &lt;strong&gt;Lombok&lt;/strong&gt; 이라는 Dependency 를 통해 Constructor, Getter, Setter 등을 쉽게 Wrapping 할 수 있었다. 이는 객체 코드를 작성할 때 많은 양의 코드를 줄여주었다.&lt;/p&gt;

&lt;p&gt;예를 들어, 객체를 아래와 같이 작성할 수 있었다.&lt;/p&gt;

&lt;div class=&quot;language-java highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;lombok.Data&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;

&lt;span class=&quot;nd&quot;&gt;@Data&lt;/span&gt;
&lt;span class=&quot;kd&quot;&gt;public&lt;/span&gt; &lt;span class=&quot;kd&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Student&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;{&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;kt&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;id&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
    &lt;span class=&quot;kd&quot;&gt;private&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;String&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;name&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;;&lt;/span&gt;
&lt;span class=&quot;o&quot;&gt;}&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;이렇게 하면 기본적인 Constructor, Getter, Setter 등을 &lt;em&gt;@Data Annotation&lt;/em&gt; 을 통해서 쉽게 할 수 있었다. 이처럼 Java 로 개발할 때는 이런 도구들이 개발 효율성을 높여주었다.&lt;/p&gt;

&lt;p&gt;지금은 소프트웨어 엔지니어링을 하지 않고 신경망 설계 및 실험을 진행하고 있지만 이 경우에도 당연히 많은 코드가 쓰이며 그렇기 때문에 어떻게 코드를 효율적으로 빠르게 작성할 수 있는가에 대하여 고민하는 것은 당연한 것 같다.&lt;/p&gt;

&lt;p&gt;기존의 Python3 에서 객체 코드를 작성할 때는 아래와 같이 작성하였다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.nn&lt;/span&gt; &lt;span class=&quot;k&quot;&gt;as&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;

&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;nn&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Module&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
  &lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
    &lt;span class=&quot;nb&quot;&gt;super&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
    &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;
    &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;k&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;
    &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;v&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;위와 같은 코드를 작성하면서 시간이 많이 걸렸다고 생각되는 구간은 Constructor 이다. Property 를 일일히 Assgin 해주고 있었기 때문에 손가락을 많이 움직여야했다.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;Java 에도 있는데 Python 에도 혹시 편하게 해주는 것은 없을까? 라는 생각은 계속 해왔었다.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;이러한 문제를 없애주기 해소하기 위하여 Python 3.7 부터 추가된 &lt;a href=&quot;https://docs.python.org/ko/3/library/dataclasses.html&quot;&gt;dataclasses&lt;/a&gt; 라는 Pacakge 를 사용해보도록 하자.&lt;/p&gt;

&lt;p&gt;이 글에서는 간단한 사용 방법만 소개하도록 한다.&lt;/p&gt;

&lt;h2 id=&quot;2-how-to-use&quot;&gt;2. How to use?&lt;/h2&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;dataclasses&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;dataclass&lt;/span&gt;

&lt;span class=&quot;o&quot;&gt;@&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataclass&lt;/span&gt;
&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;Net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;
    &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;Java 와 비슷하게 &lt;em&gt;@dataclass&lt;/em&gt; Decorator 로 객체를 Wrapping 해준다.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;print&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[]))&lt;/span&gt;
&lt;span class=&quot;n&quot;&gt;Result&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Net&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;k&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[],&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;v&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[])&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;결과는 위와 같이 나오며 성공적으로 Constructor 가 설정되었음을 알 수 있었다.&lt;/p&gt;

&lt;h2 id=&quot;3-reference&quot;&gt;3. Reference&lt;/h2&gt;

&lt;ol&gt;
  &lt;li&gt;&lt;a href=&quot;https://docs.python.org/ko/3/library/dataclasses.html&quot;&gt;Python Doc - dataclasses&lt;/a&gt;&lt;/li&gt;
&lt;/ol&gt;</content><author><name></name></author><summary type="html">1. Introduction</summary></entry><entry><title type="html">CS224W - Machine Learning w/ Graph (1)</title><link href="https://judepark96.github.io/blog/embedding/machine-learning/deep-learning/graph/2020/04/15/CS224W-Machine-Learning-with-Graph-(1).html" rel="alternate" type="text/html" title="CS224W - Machine Learning w/ Graph (1)" /><published>2020-04-15T00:00:00-05:00</published><updated>2020-04-15T00:00:00-05:00</updated><id>https://judepark96.github.io/blog/embedding/machine-learning/deep-learning/graph/2020/04/15/CS224W-Machine%20-Learning-with-Graph-(1)</id><content type="html" xml:base="https://judepark96.github.io/blog/embedding/machine-learning/deep-learning/graph/2020/04/15/CS224W-Machine-Learning-with-Graph-(1).html">&lt;ul&gt;
  &lt;li&gt;Why Networks?&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Networks are a general language for describing complex systems of interacting entities.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;Networks
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Society&lt;/strong&gt; :→ collection of 7+ billion individuals.&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Communication systems&lt;/strong&gt; :→ it links electronic devices&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Interaction&lt;/strong&gt; :→ between genes/proteins regulate life&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Thoughts&lt;/strong&gt; :→ it is hidden in the connections between billions of neurons in our brain&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Type of Networks
    &lt;ul&gt;
      &lt;li&gt;Social networks&lt;/li&gt;
      &lt;li&gt;Economic networks&lt;/li&gt;
      &lt;li&gt;Communication networks&lt;/li&gt;
      &lt;li&gt;Information networks&lt;/li&gt;
      &lt;li&gt;Internet&lt;/li&gt;
      &lt;li&gt;Networks of neurons&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Way to Analyze Networks
    &lt;ul&gt;
      &lt;li&gt;&lt;strong&gt;Node classification&lt;/strong&gt; :→ predict the type/color of a given node&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Link prediction&lt;/strong&gt; :→ predict whether two nodes are linked&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Community detection&lt;/strong&gt; :→ identify densely linked clusters of nodes&lt;/li&gt;
      &lt;li&gt;&lt;strong&gt;Network Similarity&lt;/strong&gt; :→ measure similarity of two nodes/networks&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Embedding Node
    &lt;ul&gt;
      &lt;li&gt;Let there is $Node u$, $Node v$.  When embedding, our goal is mapping nodes to $d$-dimensional embeddings such that nodes with similar network neighbourhoods are embedded close together.
        &lt;ul&gt;
          &lt;li&gt;&lt;strong&gt;My thinking&lt;/strong&gt; :→ As I think, in Natural Language Area, between each word of given sentence, they have a certain &lt;strong&gt;relationship&lt;/strong&gt; which they have to be represented by network representation.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Components of a Network
    &lt;ul&gt;
      &lt;li&gt;Object ($N$)
        &lt;ul&gt;
          &lt;li&gt;nodes, vertices&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Interactions ($E$)
        &lt;ul&gt;
          &lt;li&gt;links, edges&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;System ($G(N, E)$)
        &lt;ul&gt;
          &lt;li&gt;network, graph&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Directed VS Undirected Graphs
    &lt;ul&gt;
      &lt;li&gt;Directed
        &lt;ul&gt;
          &lt;li&gt;links :→ directed /w arcs&lt;/li&gt;
          &lt;li&gt;examples :→ phone calls, following on Twitter.&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
      &lt;li&gt;Undirected
        &lt;ul&gt;
          &lt;li&gt;links :→ undirected which means it is symmetrical, reciprocal matrix.&lt;/li&gt;
          &lt;li&gt;example :→ collaborations, friendship on Facebook&lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Bipartite Graph
    &lt;ul&gt;
      &lt;li&gt;it is a graph whose nodes can be divided into two disjoint sets $U$ and $V$ such that every link connects a node in $U$ to one in $V$ which means $U$ and $V$ are &lt;strong&gt;independent sets.&lt;/strong&gt;&lt;/li&gt;
      &lt;li&gt;Examples
        &lt;ul&gt;
          &lt;li&gt;Authors - Papers&lt;/li&gt;
          &lt;li&gt;Actors - Movies&lt;/li&gt;
          &lt;li&gt;Users - Moveis&lt;/li&gt;
          &lt;li&gt;Recipes - Ingredients&lt;/li&gt;
          &lt;li&gt;Folded Network
            &lt;ul&gt;
              &lt;li&gt;Author collaboration networks&lt;/li&gt;
              &lt;li&gt;Movie co-rating networks&lt;/li&gt;
            &lt;/ul&gt;
          &lt;/li&gt;
        &lt;/ul&gt;
      &lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
  &lt;li&gt;Conclusion
    &lt;ul&gt;
      &lt;li&gt;As mentioned above, Networks are a general language for describing complex systems of interacting entities. No matter what you are in position it means domain, well-representation by graph will be powerful method to solve the given tasks.&lt;/li&gt;
    &lt;/ul&gt;
  &lt;/li&gt;
&lt;/ul&gt;</content><author><name></name></author><summary type="html">Why Networks?</summary></entry><entry><title type="html">An Efficient Framework for Learning Sentence Representations</title><link href="https://judepark96.github.io/blog/embedding/nlp/deep-learning/2020/04/14/An-Efficient-Framework-for-Learning-Sentence-Representations.html" rel="alternate" type="text/html" title="An Efficient Framework for Learning Sentence Representations" /><published>2020-04-14T00:00:00-05:00</published><updated>2020-04-14T00:00:00-05:00</updated><id>https://judepark96.github.io/blog/embedding/nlp/deep-learning/2020/04/14/An-Efficient-Framework-for-Learning-Sentence-Representations</id><content type="html" xml:base="https://judepark96.github.io/blog/embedding/nlp/deep-learning/2020/04/14/An-Efficient-Framework-for-Learning-Sentence-Representations.html">&lt;script async=&quot;&quot; class=&quot;speakerdeck-embed&quot; data-id=&quot;c83e26401b0a4168a3d48c26253be6d8&quot; data-ratio=&quot;1.41436464088398&quot; src=&quot;//speakerdeck.com/assets/embed.js&quot;&gt;&lt;/script&gt;

&lt;h2 id=&quot;1-summary&quot;&gt;1. Summary&lt;/h2&gt;

&lt;p&gt;자연어처리의 여러 과업들을 연구하는 일의 필수적인 요소는 &lt;strong&gt;임베딩&lt;/strong&gt;이다. Discrete Variables 를 Continuous Vectors 로 다룰 수 있게 해주며 신경망을 통하여 구축한 임베딩은 각 Vector 가 의미를 가지고 있다. 이러한 임베딩 기법에는 &lt;strong&gt;Word2Vec, Glove, FastText&lt;/strong&gt; 가 있는데 이 중의 Word2Vec 을 간단히 살펴보고 간다.&lt;/p&gt;

&lt;p&gt;Word2Vec[1] 에서 &lt;strong&gt;Distributional Hypothesis&lt;/strong&gt; 를 기반하여 Unsupervised Learning 을 하는 신경망을 구축하였다. 그렇다면 Distributional Hypothesis 는 무엇일까? &lt;strong&gt;비슷한 위치에서 발생하는 단어들은 그 의미도 유사할 것이라는 가정&lt;/strong&gt;이다. 간단한 예시를 아래에서 잠깐 언급해보겠다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;나는 [빈 칸] 을 보았어. - 예시 1&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;예시 1의 문장에 빈 칸에 어떠한 단어를 넣을까? 굉장히 수많은 단어가 가능할 것이다. 예를 들어 개, 고양이 등이 가능할 것이다. 위의 예시 1처럼 주변의 단어를 가지고 [빈 칸] 의 단어를 예측하는 것이 Word2Vec 의 &lt;strong&gt;CBOW(Continuous Bag of Words)&lt;/strong&gt; 이다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;[빈 칸] 고양이 [빈 칸] - 예시 2&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;예시 1과 다르게 예시 2는 주어진 단어를 바탕으로 주변 단어들이 무엇인지 예측하는 것이 Word2Vec 의 &lt;strong&gt;Skip-Gram&lt;/strong&gt; 이다.&lt;/p&gt;

&lt;p&gt;An Efficient Framework for Learning Sentence Representations 에서는 이러한 Distributional Hypothesis 를 Consecutive Sentences 에 적용한다. 그렇다면 Sentence Embedding 에서의 Distributional Hypothesis 는 &lt;strong&gt;비슷한 맥락에 있는 문장들은 그 의미도 유사할 것이라는 가정&lt;/strong&gt;으로 생각할 수 있다. 이 가정을 바탕으로 신경망을 구축한다.&lt;/p&gt;

&lt;p&gt;신경망과 관련된 자세한 이야기는 슬라이드를 참고하면 될 것 같다.&lt;/p&gt;

&lt;h2 id=&quot;2-reference&quot;&gt;2. Reference&lt;/h2&gt;

&lt;p&gt;[1]. Efficient Estimation of Word Representations in Vector Space&lt;/p&gt;</content><author><name></name></author><summary type="html"></summary></entry><entry><title type="html">How to write custom dataset class?</title><link href="https://judepark96.github.io/blog/2020/03/26/powerful-method-dataloader-dataset.html" rel="alternate" type="text/html" title="How to write custom dataset class?" /><published>2020-03-26T00:00:00-05:00</published><updated>2020-03-26T00:00:00-05:00</updated><id>https://judepark96.github.io/blog/2020/03/26/powerful-method-dataloader-dataset</id><content type="html" xml:base="https://judepark96.github.io/blog/2020/03/26/powerful-method-dataloader-dataset.html">&lt;h1 id=&quot;1-introduction&quot;&gt;1. Introduction&lt;/h1&gt;
&lt;p&gt;Everyone knows deep learning is getting important nowadays. There is a two popular framework to write the code for deep learning as:&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;PyTorch&lt;/li&gt;
  &lt;li&gt;TensorFlow&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Many of code in GitHub has written in PyTorch or TensorFlow, So the fact is when we want to write simple neural network such as multi-layer perceptron, we should know PyTorch or TensorFlow. It’s being simple common sense.&lt;/p&gt;

&lt;p&gt;Before writing the neural network, data has to be prepared for training. In this post, I will introduce &lt;strong&gt;how to write custom dataset class&lt;/strong&gt; using PyTorch simply.&lt;/p&gt;

&lt;h1 id=&quot;2-defining-data-format&quot;&gt;2. Defining Data Format&lt;/h1&gt;

&lt;p&gt;The problem is what the format is various. For example, the image has usually $width \times height \times channel$, the text has usually $1 \times \text{text length}$ at all.
In this post, data format is &lt;strong&gt;question/answering&lt;/strong&gt; such as simple chatbot.&lt;/p&gt;

&lt;p&gt;Given data format is as:&lt;/p&gt;

&lt;table&gt;
  &lt;thead&gt;
    &lt;tr&gt;
      &lt;th&gt;Question&lt;/th&gt;
      &lt;th&gt;Answering&lt;/th&gt;
    &lt;/tr&gt;
  &lt;/thead&gt;
  &lt;tbody&gt;
    &lt;tr&gt;
      &lt;td&gt;12시 땡!&lt;/td&gt;
      &lt;td&gt;하루가 또 가네요.&lt;/td&gt;
    &lt;/tr&gt;
  &lt;/tbody&gt;
&lt;/table&gt;

&lt;blockquote&gt;
  &lt;p&gt;In english, Each means “It’s 12 pm!”, “One another day passed.”&lt;/p&gt;
&lt;/blockquote&gt;

&lt;h1 id=&quot;3-writing-custom-dataset-class&quot;&gt;3. Writing Custom Dataset Class!&lt;/h1&gt;

&lt;p&gt;In this section, we will explore dataset class, and how to write with respect to given function of class.&lt;/p&gt;

&lt;p&gt;First, Dataset is class of pre-prcoessing data in PyTorch. We can write as:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;kn&quot;&gt;from&lt;/span&gt; &lt;span class=&quot;nn&quot;&gt;torch.utils.data&lt;/span&gt; &lt;span class=&quot;kn&quot;&gt;import&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Dataset&lt;/span&gt;


&lt;span class=&quot;k&quot;&gt;class&lt;/span&gt; &lt;span class=&quot;nc&quot;&gt;ConversationDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;Dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;
	&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;pass&lt;/span&gt;
  
	&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__getitem__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Any&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
		&lt;span class=&quot;k&quot;&gt;pass&lt;/span&gt;
  
	&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__len__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;
	    &lt;span class=&quot;k&quot;&gt;pass&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;The class name is whatever you want. If you want to another name such as &lt;strong&gt;QuestionAnsweingDataset&lt;/strong&gt;, It’s fine. &lt;strong&gt;Just remember, class name should include what the class means.&lt;/strong&gt;&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;def __init__(self, args1, args2, ...)&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It means initiating class with given arguments. As you know, at this function, initiating properties of class with given arguments. Arguments might be necessity to pre-processing given data.&lt;/p&gt;

&lt;p&gt;If we need &lt;strong&gt;question, answer, vocab, max_len&lt;/strong&gt; as arguments, the code is as:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__init__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;question&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;answer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vocab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Vocabulary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;mi&quot;&gt;128&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;None&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;  
	&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;question&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;question&lt;/span&gt;  
	&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;answer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;answer&lt;/span&gt;  
	&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vocab&lt;/span&gt;  
	&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_len&lt;/span&gt;  
	&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Mecab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;blockquote&gt;
  &lt;p&gt;Using type-hinting, It’s very useful when writing easy to understand.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;__getitem__(self, idx: int) -&amp;gt; Any&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;This function returns single sequence data. Also, data has to be pre-processed for training at this function.
Idx, the argument is given data index.&lt;/p&gt;

&lt;p&gt;What we need is tokenized each text data, the code is as:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__getitem__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;):&lt;/span&gt;  
	&lt;span class=&quot;n&quot;&gt;q_tokenized&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;special_tokens&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;2&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;morphs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;question&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;  
    &lt;span class=&quot;n&quot;&gt;a_tokenized&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;tokenizer&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;morphs&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;answer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;+&lt;/span&gt; &lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;special_tokens&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[&lt;/span&gt;&lt;span class=&quot;mi&quot;&gt;3&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]]&lt;/span&gt;  
  
    &lt;span class=&quot;n&quot;&gt;q_len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q_tokenized&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  
    &lt;span class=&quot;n&quot;&gt;a_len&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a_tokenized&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  
  
    &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;long&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  
    &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;ones&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;max_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;long&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;()&lt;/span&gt;  
  
    &lt;span class=&quot;n&quot;&gt;q_tensor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LongTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_token2idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  
                             &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q_tokenized&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;  
  
    &lt;span class=&quot;n&quot;&gt;a_tensor&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;T&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;LongTensor&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;([&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;vocab&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;get_token2idx&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;word&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  
                             &lt;span class=&quot;k&quot;&gt;for&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;word&lt;/span&gt; &lt;span class=&quot;ow&quot;&gt;in&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a_tokenized&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;])&lt;/span&gt;
	&lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;q_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q_tensor&lt;/span&gt;  
	&lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;[:&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;a_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;]&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a_tensor&lt;/span&gt;  
  
	&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;q&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;a&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;In text pre-processing, we need to convert the text to index of given vocabulary to understand, because computer actually doesn’t know what the sentence means if we don’t covert.&lt;/p&gt;

&lt;p&gt;First, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;q_tokenized&lt;/code&gt; is tokenizing given sentence by morpheme unit. For example, &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;나는 한국어를 공부해&lt;/code&gt; will be &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;['나', '는', '한국어', '를', '공부', '해']&lt;/code&gt;&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;T.ones(self.max_len).long()&lt;/code&gt; is for text padding such as zero-padding of computer vision. Each given length of sentence is various. Some of sentence could be 128, or 64, or 48, and so on. So, we need to define maximum length of sentence with argument of initiating function. In this post, maximum length of sentence is 128.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;T.ones(self.max_len).long()&lt;/code&gt; returns $[1 \times \text{maximum length}]$ shape which contains only 1. The reason I called &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;T.ones&lt;/code&gt; function, index of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;&amp;lt;pad&amp;gt;&lt;/code&gt;token is 1.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;q_tensor&lt;/code&gt; is just storing sentence coverted from tokenized word to following vocabulary index. Shape of &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;q_tensor&lt;/code&gt; is $[1 \times \text{sentence length}]$. Length of sentence could equal to maximum length which we define luckily, but it’s highly unlikely.&lt;/p&gt;

&lt;p&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;q[:q_len]  = q_tensor&lt;/code&gt;, this statement solve above problem. it returns like &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;[4, 5, 6, 7, 8, 9, 1, 1, ... , 1]&lt;/code&gt; and it equals to &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;['나', '는', '한국어', '를', '공부', '해', &amp;lt;pad&amp;gt;, &amp;lt;pad&amp;gt;, ..., &amp;lt;pad&amp;gt;]&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Pre-processing is done! Now, all we need to write is &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;return q&lt;/code&gt;.&lt;/p&gt;

&lt;blockquote&gt;
  &lt;p&gt;You can do the same process with the above method for pre-processing answer.&lt;/p&gt;
&lt;/blockquote&gt;

&lt;ul&gt;
  &lt;li&gt;&lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;def __len__(self) -&amp;gt; int&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;It returns lengths of whole data. I usually use &lt;strong&gt;assert statement&lt;/strong&gt; which means, training data and label usually have same length.&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;__len__&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;  
	&lt;span class=&quot;k&quot;&gt;assert&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;question&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;==&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;answer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;bp&quot;&gt;self&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;.&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;question&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;p&gt;The benefit of using assert statement is when initiating class and call, we can protect ourselves from potential issue. Because, given data format has ground truth: one question - one answer.
So, if we have 1200 questions, then it must have 1200 answers. it’s kids stuff right?&lt;/p&gt;

&lt;h1 id=&quot;4-initiating-dataloader-using-custom-dataset&quot;&gt;4. Initiating DataLoader using Custom Dataset&lt;/h1&gt;

&lt;p&gt;DataLoader is simple, powerful method to bring the batch data automatically. Let’s see the code as:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;def&lt;/span&gt; &lt;span class=&quot;nf&quot;&gt;get_loader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;question&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  
               &lt;span class=&quot;n&quot;&gt;answer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;list&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  
               &lt;span class=&quot;n&quot;&gt;vocab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;Vocabulary&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  
               &lt;span class=&quot;n&quot;&gt;max_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;&lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  
               &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;int&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt;  
               &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt; &lt;span class=&quot;nb&quot;&gt;bool&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;-&amp;gt;&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;:&lt;/span&gt;  
	&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt; &lt;span class=&quot;o&quot;&gt;=&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;ConversationDataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;question&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;answer&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;vocab&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;max_len&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;  
    &lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;First, we need to initiate dataset class as mentioned at section 3. Then, we have &lt;code class=&quot;language-plaintext highlighter-rouge&quot;&gt;dataset&lt;/code&gt; variable in function.
All we left is initiating dataloader class following as:&lt;/p&gt;

&lt;div class=&quot;language-python highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;&lt;span class=&quot;k&quot;&gt;return&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;DataLoader&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;(&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;dataset&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;batch_size&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;,&lt;/span&gt; &lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;o&quot;&gt;=&lt;/span&gt;&lt;span class=&quot;n&quot;&gt;shuffle&lt;/span&gt;&lt;span class=&quot;p&quot;&gt;)&lt;/span&gt;
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;

&lt;h1 id=&quot;5-summary&quot;&gt;5. Summary&lt;/h1&gt;

&lt;p&gt;In this post, we figured out how to write custom dataset class in PyTorch, and using dataloader class. It’s very convenient, powerful method. It reduces code complexity which means easy to understand.&lt;/p&gt;</content><author><name></name></author><category term="PyTorch" /><category term="Deep Learning" /><category term="NLP" /><summary type="html">1. Introduction Everyone knows deep learning is getting important nowadays. There is a two popular framework to write the code for deep learning as:</summary></entry><entry><title type="html">BLEU (Bilingual Evaluation Understudy) Score</title><link href="https://judepark96.github.io/blog/2020/03/22/BLEU-Score-Reasonable.html" rel="alternate" type="text/html" title="BLEU (Bilingual Evaluation Understudy) Score" /><published>2020-03-22T00:00:00-05:00</published><updated>2020-03-22T00:00:00-05:00</updated><id>https://judepark96.github.io/blog/2020/03/22/BLEU-Score-Reasonable</id><content type="html" xml:base="https://judepark96.github.io/blog/2020/03/22/BLEU-Score-Reasonable.html">&lt;blockquote&gt;
  &lt;p&gt;연구 주제에 맞게 읽을 논문을 추천해주신 카카오의 &lt;a href=&quot;https://www.facebook.com/dongyub.lee.9&quot;&gt;이동엽&lt;/a&gt; 형에게 감사드립니다! :)&lt;/p&gt;
&lt;/blockquote&gt;

&lt;p&gt;최근, 연구 주제를 정하며 대화형 데이터에 대한 evaluation metric에 대하여 생각해볼 필요가 있어짐에 따라 BLEU Score에 대하여 찾아보게 되었다. BLEU에 대한 설명과 어떠한 문제점을 내포하고 있는지 간단하게 서술해본다.&lt;/p&gt;

&lt;script type=&quot;math/tex; mode=display&quot;&gt;BLEU = min(1, \frac{\text{output length(prediction)}}{\text{reference length(target)}})(\prod_i^4precision_i)^\frac{1}{4}&lt;/script&gt;

&lt;p&gt;BLEU 란 evaluation metric 으로서 주어진 데이터 X 가 순서성을 가진 단어로, Y 또한 X 와 마찬가지로 이루어진 경우에 사용되며 번역, 요약과 같은 과업에 사용된다.&lt;/p&gt;

&lt;ul&gt;
  &lt;li&gt;$n$-gram overlap 을 통하여 얼마나 겹치는지&lt;/li&gt;
  &lt;li&gt;문장 길이에 대한 과적합 보정&lt;/li&gt;
  &lt;li&gt;같은 단어가 연속적으로 나올 때 과적합되는 것을 보정&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&quot;is-it-really-reasonable&quot;&gt;Is It Really Reasonable?&lt;/h1&gt;

&lt;p&gt;BLEU 의 수식을 간단히 요약하자면 Target Sentence 와 Predicted Sentence 사이의 $n$-gram overlap 을 통하여 문장의 유사성을 살펴보는 것이다. 그렇다면, 이는 과연 합리적인 evaluation metric 인지 고심해봐야한다.&lt;/p&gt;

&lt;p&gt;기존의 방법론에 대하여 문제 제기를 한 첫 논문은 RUBER[1] 이며 이를 바탕으로 BERT 와 같은 Contextualized Embedding 을 이용하여 제안한 것이 [2] 이다. 이 글에서는 [2]의 논문의 예시를 인용하였다.&lt;/p&gt;

&lt;div class=&quot;language-plaintext highlighter-rouge&quot;&gt;&lt;div class=&quot;highlight&quot;&gt;&lt;pre class=&quot;highlight&quot;&gt;&lt;code&gt;[2] Dialogue Context
Speaker 1: Hey! What are you doing here?
Speaker 2: I'm just shopping.
Query: What are you shopping for?
Generated Response: Some new clothes
Reference Response: I want buy gift for my mom!
&lt;/code&gt;&lt;/pre&gt;&lt;/div&gt;&lt;/div&gt;
&lt;p&gt;위의 대화 예시는 발화자 1이 “야! 너 여기서 뭐해?”라는 질문에 발화자 2가 “난 그냥 쇼핑하지.” 라는 대화이다. 그리고 다음 발화인 “쇼핑 뭐 하는데?” 라는 말에 응답 문장으로서 “그냥 새 옷 조금”라는 생성된 문장과 “어머니를 위해 옷을 사고 싶어!”라는 정답 문장이다.&lt;/p&gt;

&lt;p&gt;각자가 evaluator 가 되어 human evaluation 을 해본다면 정답 문장과 생성 문장, 모두 자연스러움을 느낄 수 있을 것이다.&lt;/p&gt;

&lt;p&gt;하지만, 위의 대화 예시를 BLEU score 로 계산해본다면 zero-score 를 받는다. 이는 $n$-gram overlap 을 이용한 평가가 human judgement 와는 correlation이 떨어진다는 것을 의미하며 evaluation stage 에서 semantic methodology 가 고려되야한다는 것을 알 수 있다.&lt;/p&gt;

&lt;h1 id=&quot;reference&quot;&gt;Reference&lt;/h1&gt;
&lt;p&gt;[1]. &lt;a href=&quot;https://arxiv.org/abs/1701.03079&quot;&gt;RUBER: An Unsupervised Method for Automatic Evaluation of Open-Domain Dialog Systems&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;[2]. &lt;a href=&quot;https://arxiv.org/abs/1904.10635&quot;&gt;Better Automatic Evaluation of Open-Domain Dialogue Systems with Contextualized Embeddings&lt;/a&gt;&lt;/p&gt;</content><author><name></name></author><category term="Deep Learning" /><category term="NLP" /><category term="Evaluation Metric" /><summary type="html">연구 주제에 맞게 읽을 논문을 추천해주신 카카오의 이동엽 형에게 감사드립니다! :)</summary></entry></feed>