<!DOCTYPE html>
<html lang="en"><head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1"><link rel="shortcut icon" type="image/x-icon" href="/blog/favicon.ico"><!-- Begin Jekyll SEO tag v2.6.1 -->
<title>How to write custom dataset class? | Eunhwan Park X NLP</title>
<meta name="generator" content="Jekyll v3.8.5" />
<meta property="og:title" content="How to write custom dataset class?" />
<meta property="og:locale" content="en_US" />
<meta name="description" content="Powerful method &lt;DataLoader, Dataset&gt; - PyTorch" />
<meta property="og:description" content="Powerful method &lt;DataLoader, Dataset&gt; - PyTorch" />
<link rel="canonical" href="https://judepark96.github.io/blog/2020/03/26/powerful-method-dataloader-dataset.html" />
<meta property="og:url" content="https://judepark96.github.io/blog/2020/03/26/powerful-method-dataloader-dataset.html" />
<meta property="og:site_name" content="Eunhwan Park X NLP" />
<meta property="og:type" content="article" />
<meta property="article:published_time" content="2020-03-26T00:00:00-05:00" />
<script type="application/ld+json">
{"url":"https://judepark96.github.io/blog/2020/03/26/powerful-method-dataloader-dataset.html","@type":"BlogPosting","headline":"How to write custom dataset class?","dateModified":"2020-03-26T00:00:00-05:00","datePublished":"2020-03-26T00:00:00-05:00","mainEntityOfPage":{"@type":"WebPage","@id":"https://judepark96.github.io/blog/2020/03/26/powerful-method-dataloader-dataset.html"},"description":"Powerful method &lt;DataLoader, Dataset&gt; - PyTorch","@context":"https://schema.org"}</script>
<!-- End Jekyll SEO tag -->

  <link href="https://unpkg.com/@primer/css/dist/primer.css" rel="stylesheet" />
  <link rel="stylesheet" href="/blog/assets/main.css">
  <link rel="stylesheet" href="//use.fontawesome.com/releases/v5.0.7/css/all.css"><link type="application/atom+xml" rel="alternate" href="https://judepark96.github.io/blog/feed.xml" title="Eunhwan Park X NLP" />
    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.css" integrity="sha384-zB1R0rpPzHqg7Kpt0Aljp8JPLqbXI3bhnPWROx27a9N0Ll6ZP/+DiW/UqRcLbRjq" crossorigin="anonymous">
    <script type="text/javascript" async src="https://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-MML-AM_CHTML"> </script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/katex.min.js" integrity="sha384-y23I5Q6l+B6vatafAwxRu/0oK/79VlbSz7Q9aiSZUvyWYIYsd+qj+o24G5ZU2zJz" crossorigin="anonymous"></script>
    <script defer src="https://cdn.jsdelivr.net/npm/katex@0.11.1/dist/contrib/auto-render.min.js" integrity="sha384-kWPLUVMOks5AQFrykwIup5lo0m3iMkkHrD0uJ4H5cjeGihAutqP0yW0J6dpFiVkI" crossorigin="anonymous"></script>
    <script>
      document.addEventListener("DOMContentLoaded", function() {
        renderMathInElement( document.body, {
          delimiters: [
            {left: "$$", right: "$$", display: true},
            {left: "[%", right: "%]", display: true},
            {left: "$", right: "$", display: false}
          ]}
        );
      });
    </script>
  

  <script>
  function wrap_img(fn) {
    if (document.attachEvent ? document.readyState === "complete" : document.readyState !== "loading") {
        var elements = document.querySelectorAll(".post img");
        Array.prototype.forEach.call(elements, function(el, i) {
            if (el.getAttribute("title")) {
                const caption = document.createElement('figcaption');
                var node = document.createTextNode(el.getAttribute("title"));
                caption.appendChild(node);
                const wrapper = document.createElement('figure');
                wrapper.className = 'image';
                el.parentNode.insertBefore(wrapper, el);
                el.parentNode.removeChild(el);
                wrapper.appendChild(el);
                wrapper.appendChild(caption);
            }
        });
    } else { document.addEventListener('DOMContentLoaded', fn); }
  }
  window.onload = wrap_img;
  </script>

  <script>
    document.addEventListener("DOMContentLoaded", function(){
      // add link icon to anchor tags
      var elem = document.querySelectorAll(".anchor-link")
      elem.forEach(e => (e.innerHTML = '<i class="fas fa-link fa-xs"></i>'));
      // remove paragraph tags in rendered toc (happens from notebooks)
      var toctags = document.querySelectorAll(".toc-entry")
      toctags.forEach(e => (e.firstElementChild.innerText = e.firstElementChild.innerText.replace('¶', '')))
    });
  </script>
</head><body><header class="site-header" role="banner">

  <div class="wrapper"><a class="site-title" rel="author" href="/blog/">Eunhwan Park X NLP</a><nav class="site-nav">
        <input type="checkbox" id="nav-trigger" class="nav-trigger" />
        <label for="nav-trigger">
          <span class="menu-icon">
            <svg viewBox="0 0 18 15" width="18px" height="15px">
              <path d="M18,1.484c0,0.82-0.665,1.484-1.484,1.484H1.484C0.665,2.969,0,2.304,0,1.484l0,0C0,0.665,0.665,0,1.484,0 h15.032C17.335,0,18,0.665,18,1.484L18,1.484z M18,7.516C18,8.335,17.335,9,16.516,9H1.484C0.665,9,0,8.335,0,7.516l0,0 c0-0.82,0.665-1.484,1.484-1.484h15.032C17.335,6.031,18,6.696,18,7.516L18,7.516z M18,13.516C18,14.335,17.335,15,16.516,15H1.484 C0.665,15,0,14.335,0,13.516l0,0c0-0.82,0.665-1.483,1.484-1.483h15.032C17.335,12.031,18,12.695,18,13.516L18,13.516z"/>
            </svg>
          </span>
        </label>

        <div class="trigger"><a class="page-link" href="/blog/about/">About Me</a><a class="page-link" href="/blog/">Posts</a><a class="page-link" href="/blog/search/">Search</a><a class="page-link" href="/blog/categories/">Tags</a><a class="page-link" href="/blog/travel_log/">Travel Log</a></div>
      </nav></div>
</header>
<main class="page-content" aria-label="Content">
      <div class="wrapper">
        <article class="post h-entry" itemscope itemtype="http://schema.org/BlogPosting">

  <header class="post-header">
    <h1 class="post-title p-name" itemprop="name headline">How to write custom dataset class?</h1><p class="page-description">Powerful method &lt;DataLoader, Dataset&gt; - PyTorch</p><p class="post-meta post-meta-title"><time class="dt-published" datetime="2020-03-26T00:00:00-05:00" itemprop="datePublished">
        Mar 26, 2020
      </time>
       • <span class="read-time" title="Estimated read time">
    
    
      4 min read
    
</span></p>

    

    </header>

  <div class="post-content e-content" itemprop="articleBody">
    <ul class="section-nav">
<li class="toc-entry toc-h1"><a href="#1-introduction">1. Introduction</a></li>
<li class="toc-entry toc-h1"><a href="#2-defining-data-format">2. Defining Data Format</a></li>
<li class="toc-entry toc-h1"><a href="#3-writing-custom-dataset-class">3. Writing Custom Dataset Class!</a></li>
<li class="toc-entry toc-h1"><a href="#4-initiating-dataloader-using-custom-dataset">4. Initiating DataLoader using Custom Dataset</a></li>
<li class="toc-entry toc-h1"><a href="#5-summary">5. Summary</a></li>
</ul><h1 id="1-introduction">
<a class="anchor" href="#1-introduction" aria-hidden="true"><span class="octicon octicon-link"></span></a>1. Introduction</h1>
<p>Everyone knows deep learning is getting important nowadays. There is a two popular framework to write the code for deep learning as:</p>

<ul>
  <li>PyTorch</li>
  <li>TensorFlow</li>
</ul>

<p>Many of code in GitHub has written in PyTorch or TensorFlow, So the fact is when we want to write simple neural network such as multi-layer perceptron, we should know PyTorch or TensorFlow. It’s being simple common sense.</p>

<p>Before writing the neural network, data has to be prepared for training. In this post, I will introduce <strong>how to write custom dataset class</strong> using PyTorch simply.</p>

<h1 id="2-defining-data-format">
<a class="anchor" href="#2-defining-data-format" aria-hidden="true"><span class="octicon octicon-link"></span></a>2. Defining Data Format</h1>

<p>The problem is what the format is various. For example, the image has usually $width \times height \times channel$, the text has usually $1 \times \text{text length}$ at all.
In this post, data format is <strong>question/answering</strong> such as simple chatbot.</p>

<p>Given data format is as:</p>

<table>
  <thead>
    <tr>
      <th>Question</th>
      <th>Answering</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>12시 땡!</td>
      <td>하루가 또 가네요.</td>
    </tr>
  </tbody>
</table>

<blockquote>
  <p>In english, Each means “It’s 12 pm!”, “One another day passed.”</p>
</blockquote>

<h1 id="3-writing-custom-dataset-class">
<a class="anchor" href="#3-writing-custom-dataset-class" aria-hidden="true"><span class="octicon octicon-link"></span></a>3. Writing Custom Dataset Class!</h1>

<p>In this section, we will explore dataset class, and how to write with respect to given function of class.</p>

<p>First, Dataset is class of pre-prcoessing data in PyTorch. We can write as:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">from</span> <span class="nn">torch.utils.data</span> <span class="kn">import</span> <span class="n">Dataset</span>


<span class="k">class</span> <span class="nc">ConversationDataset</span><span class="p">(</span><span class="n">Dataset</span><span class="p">):</span>
	<span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>
		<span class="k">pass</span>
  
	<span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">Any</span><span class="p">:</span>
		<span class="k">pass</span>
  
	<span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>
	    <span class="k">pass</span>
</code></pre></div></div>
<p>The class name is whatever you want. If you want to another name such as <strong>QuestionAnsweingDataset</strong>, It’s fine. <strong>Just remember, class name should include what the class means.</strong></p>

<ul>
  <li><code class="language-plaintext highlighter-rouge">def __init__(self, args1, args2, ...)</code></li>
</ul>

<p>It means initiating class with given arguments. As you know, at this function, initiating properties of class with given arguments. Arguments might be necessity to pre-processing given data.</p>

<p>If we need <strong>question, answer, vocab, max_len</strong> as arguments, the code is as:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">__init__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">question</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">answer</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span> <span class="n">vocab</span><span class="p">:</span> <span class="n">Vocabulary</span><span class="p">,</span> <span class="n">max_len</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="mi">128</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="bp">None</span><span class="p">:</span>  
	<span class="bp">self</span><span class="o">.</span><span class="n">question</span> <span class="o">=</span> <span class="n">question</span>  
	<span class="bp">self</span><span class="o">.</span><span class="n">answer</span> <span class="o">=</span> <span class="n">answer</span>  
	<span class="bp">self</span><span class="o">.</span><span class="n">vocab</span> <span class="o">=</span> <span class="n">vocab</span>  
	<span class="bp">self</span><span class="o">.</span><span class="n">max_len</span> <span class="o">=</span> <span class="n">max_len</span>  
	<span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span> <span class="o">=</span> <span class="n">Mecab</span><span class="p">()</span>
</code></pre></div></div>
<blockquote>
  <p>Using type-hinting, It’s very useful when writing easy to understand.</p>
</blockquote>

<ul>
  <li><code class="language-plaintext highlighter-rouge">__getitem__(self, idx: int) -&gt; Any</code></li>
</ul>

<p>This function returns single sequence data. Also, data has to be pre-processed for training at this function.
Idx, the argument is given data index.</p>

<p>What we need is tokenized each text data, the code is as:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">__getitem__</span><span class="p">(</span><span class="bp">self</span><span class="p">,</span> <span class="n">idx</span><span class="p">:</span> <span class="nb">int</span><span class="p">):</span>  
	<span class="n">q_tokenized</span> <span class="o">=</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">special_tokens</span><span class="p">[</span><span class="mi">2</span><span class="p">]]</span> <span class="o">+</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">morphs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">question</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span>  
    <span class="n">a_tokenized</span> <span class="o">=</span> <span class="bp">self</span><span class="o">.</span><span class="n">tokenizer</span><span class="o">.</span><span class="n">morphs</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">answer</span><span class="p">[</span><span class="n">idx</span><span class="p">])</span> <span class="o">+</span> <span class="p">[</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">special_tokens</span><span class="p">[</span><span class="mi">3</span><span class="p">]]</span>  
  
    <span class="n">q_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">q_tokenized</span><span class="p">)</span>  
    <span class="n">a_len</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">a_tokenized</span><span class="p">)</span>  
  
    <span class="n">q</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_len</span><span class="p">)</span><span class="o">.</span><span class="nb">long</span><span class="p">()</span>  
    <span class="n">a</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">max_len</span><span class="p">)</span><span class="o">.</span><span class="nb">long</span><span class="p">()</span>  
  
    <span class="n">q_tensor</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">get_token2idx</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>  
                             <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">q_tokenized</span><span class="p">])</span>  
  
    <span class="n">a_tensor</span> <span class="o">=</span> <span class="n">T</span><span class="o">.</span><span class="n">LongTensor</span><span class="p">([</span><span class="bp">self</span><span class="o">.</span><span class="n">vocab</span><span class="o">.</span><span class="n">get_token2idx</span><span class="p">(</span><span class="n">word</span><span class="p">)</span>  
                             <span class="k">for</span> <span class="n">word</span> <span class="ow">in</span> <span class="n">a_tokenized</span><span class="p">])</span>
	<span class="n">q</span><span class="p">[:</span><span class="n">q_len</span><span class="p">]</span> <span class="o">=</span> <span class="n">q_tensor</span>  
	<span class="n">a</span><span class="p">[:</span><span class="n">a_len</span><span class="p">]</span> <span class="o">=</span> <span class="n">a_tensor</span>  
  
	<span class="k">return</span> <span class="n">q</span><span class="p">,</span> <span class="n">a</span>
</code></pre></div></div>
<p>In text pre-processing, we need to convert the text to index of given vocabulary to understand, because computer actually doesn’t know what the sentence means if we don’t covert.</p>

<p>First, <code class="language-plaintext highlighter-rouge">q_tokenized</code> is tokenizing given sentence by morpheme unit. For example, <code class="language-plaintext highlighter-rouge">나는 한국어를 공부해</code> will be <code class="language-plaintext highlighter-rouge">['나', '는', '한국어', '를', '공부', '해']</code></p>

<p><code class="language-plaintext highlighter-rouge">T.ones(self.max_len).long()</code> is for text padding such as zero-padding of computer vision. Each given length of sentence is various. Some of sentence could be 128, or 64, or 48, and so on. So, we need to define maximum length of sentence with argument of initiating function. In this post, maximum length of sentence is 128.</p>

<p><code class="language-plaintext highlighter-rouge">T.ones(self.max_len).long()</code> returns $[1 \times \text{maximum length}]$ shape which contains only 1. The reason I called <code class="language-plaintext highlighter-rouge">T.ones</code> function, index of <code class="language-plaintext highlighter-rouge">&lt;pad&gt;</code>token is 1.</p>

<p><code class="language-plaintext highlighter-rouge">q_tensor</code> is just storing sentence coverted from tokenized word to following vocabulary index. Shape of <code class="language-plaintext highlighter-rouge">q_tensor</code> is $[1 \times \text{sentence length}]$. Length of sentence could equal to maximum length which we define luckily, but it’s highly unlikely.</p>

<p><code class="language-plaintext highlighter-rouge">q[:q_len]  = q_tensor</code>, this statement solve above problem. it returns like <code class="language-plaintext highlighter-rouge">[4, 5, 6, 7, 8, 9, 1, 1, ... , 1]</code> and it equals to <code class="language-plaintext highlighter-rouge">['나', '는', '한국어', '를', '공부', '해', &lt;pad&gt;, &lt;pad&gt;, ..., &lt;pad&gt;]</code>.</p>

<p>Pre-processing is done! Now, all we need to write is <code class="language-plaintext highlighter-rouge">return q</code>.</p>

<blockquote>
  <p>You can do the same process with the above method for pre-processing answer.</p>
</blockquote>

<ul>
  <li><code class="language-plaintext highlighter-rouge">def __len__(self) -&gt; int</code></li>
</ul>

<p>It returns lengths of whole data. I usually use <strong>assert statement</strong> which means, training data and label usually have same length.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">__len__</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="nb">int</span><span class="p">:</span>  
	<span class="k">assert</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">question</span><span class="p">)</span> <span class="o">==</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">answer</span><span class="p">)</span>  
    <span class="k">return</span> <span class="nb">len</span><span class="p">(</span><span class="bp">self</span><span class="o">.</span><span class="n">question</span><span class="p">)</span>
</code></pre></div></div>

<p>The benefit of using assert statement is when initiating class and call, we can protect ourselves from potential issue. Because, given data format has ground truth: one question - one answer.
So, if we have 1200 questions, then it must have 1200 answers. it’s kids stuff right?</p>

<h1 id="4-initiating-dataloader-using-custom-dataset">
<a class="anchor" href="#4-initiating-dataloader-using-custom-dataset" aria-hidden="true"><span class="octicon octicon-link"></span></a>4. Initiating DataLoader using Custom Dataset</h1>

<p>DataLoader is simple, powerful method to bring the batch data automatically. Let’s see the code as:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">def</span> <span class="nf">get_loader</span><span class="p">(</span><span class="n">question</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span>  
               <span class="n">answer</span><span class="p">:</span> <span class="nb">list</span><span class="p">,</span>  
               <span class="n">vocab</span><span class="p">:</span> <span class="n">Vocabulary</span><span class="p">,</span>  
               <span class="n">max_len</span><span class="p">:</span><span class="nb">int</span><span class="p">,</span>  
               <span class="n">batch_size</span><span class="p">:</span> <span class="nb">int</span><span class="p">,</span>  
               <span class="n">shuffle</span><span class="p">:</span> <span class="nb">bool</span><span class="p">)</span> <span class="o">-&gt;</span> <span class="n">DataLoader</span><span class="p">:</span>  
	<span class="n">dataset</span> <span class="o">=</span> <span class="n">ConversationDataset</span><span class="p">(</span><span class="n">question</span><span class="p">,</span> <span class="n">answer</span><span class="p">,</span> <span class="n">vocab</span><span class="p">,</span> <span class="n">max_len</span><span class="p">)</span>  
    <span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">)</span>
</code></pre></div></div>
<p>First, we need to initiate dataset class as mentioned at section 3. Then, we have <code class="language-plaintext highlighter-rouge">dataset</code> variable in function.
All we left is initiating dataloader class following as:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="k">return</span> <span class="n">DataLoader</span><span class="p">(</span><span class="n">dataset</span><span class="p">,</span> <span class="n">batch_size</span><span class="o">=</span><span class="n">batch_size</span><span class="p">,</span> <span class="n">shuffle</span><span class="o">=</span><span class="n">shuffle</span><span class="p">)</span>
</code></pre></div></div>

<h1 id="5-summary">
<a class="anchor" href="#5-summary" aria-hidden="true"><span class="octicon octicon-link"></span></a>5. Summary</h1>

<p>In this post, we figured out how to write custom dataset class in PyTorch, and using dataloader class. It’s very convenient, powerful method. It reduces code complexity which means easy to understand.</p>

  </div><a class="u-url" href="/blog/2020/03/26/powerful-method-dataloader-dataset.html" hidden></a>
</article>
      </div>
    </main><footer class="site-footer h-card">
  <data class="u-url" href="/blog/"></data>

  <div class="wrapper">

    <h2 class="footer-heading">Eunhwan Park X NLP</h2>

    <div class="footer-col-wrapper">
      <div class="footer-col footer-col-1">
        <ul class="contact-list">
          <li class="p-name">Eunhwan Park X NLP</li><li><a class="u-email" href="mailto:judepark@kookmin.ac.kr">judepark@kookmin.ac.kr</a></li></ul>
      </div>

      <div class="footer-col footer-col-2"><ul class="social-media-list">
  <li><a href="https://github.com/JudePark96"><svg class="social svg-icon"><use xlink:href="/blog/assets/minima-social-icons.svg#github"></use></svg> <span class="username">JudePark96</span></a></li></ul>
</div>

      <div class="footer-col footer-col-3">
        <p>Eunhwan Park X NLP</p>
      </div>
    </div>

  </div>

</footer>
</body>

</html>
